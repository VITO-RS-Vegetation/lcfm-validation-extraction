{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Map through STAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import geopandas as gpd\n",
    "from pystac_client import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.transform import from_bounds\n",
    "import rioxarray\n",
    "from shapely.geometry import shape\n",
    "import stackstac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_method = \"profile\"\n",
    "profile = \"lcfm\"\n",
    "\n",
    "if auth_method != \"profile\":\n",
    "    # Read s3 keys from .env files\n",
    "    load_dotenv()\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "if profile == \"gaf\":\n",
    "    endpoint_url = \"lcfm-datahub.gaf.de\"\n",
    "else:\n",
    "    endpoint_url = \"s3.waw3-1.cloudferro.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = \"../resources/LCFM_ONE_SAMPLE_Grids10m.geojson\"\n",
    "gdf_pm = gpd.read_file(shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-7287317.78886986, -651229.7052062404), (-7287217.323904815, -651230.1477818596), (-7287217.763502375, -651331.2829349549), (-7287318.228628153, -651330.8402896702)]\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "\n",
    "union = gdf_pm.union_all()\n",
    "\n",
    "# Get all coordinates from the geometry exterior\n",
    "coords = np.array(list(union.exterior.coords))\n",
    "\n",
    "# Find the corners using convex hull properties\n",
    "ch = union.convex_hull\n",
    "ch_coords = np.array(list(ch.exterior.coords))\n",
    "\n",
    "# Keep only the 4 most extreme points\n",
    "min_x_idx = np.argmin(ch_coords[:, 0])\n",
    "max_x_idx = np.argmax(ch_coords[:, 0])\n",
    "min_y_idx = np.argmin(ch_coords[:, 1])\n",
    "max_y_idx = np.argmax(ch_coords[:, 1])\n",
    "\n",
    "# Get the 4 corner points\n",
    "corner_indices = sorted(list(set([min_x_idx, max_x_idx, min_y_idx, max_y_idx])))\n",
    "\n",
    "# Check if we have exactly 4 corners\n",
    "if len(corner_indices) < 4:\n",
    "    # Alternative approach: get the actual corners from a simplified polygon\n",
    "    simplified = union.simplify(union.length / 100)  # Simplify to get fewer points\n",
    "    simple_coords = np.array(list(simplified.exterior.coords))\n",
    "    \n",
    "    # Find points furthest from centroid\n",
    "    centroid = simplified.centroid\n",
    "    distances = [point.distance(centroid) for point in [Polygon([simple_coords[i:i+2]]) for i in range(len(simple_coords)-1)]]\n",
    "    sorted_indices = np.argsort(distances)[-4:]  # Get 4 points furthest from centroid\n",
    "    corner_points = [tuple(simple_coords[i]) for i in sorted_indices]\n",
    "else:\n",
    "    corner_points = [tuple(ch_coords[i]) for i in corner_indices]\n",
    "\n",
    "# Get the centroid for initialization\n",
    "centroid = union.centroid\n",
    "centroid_point = (centroid.x, centroid.y)\n",
    "\n",
    "# Initialize points with the centroid coordinates (will be replaced by actual corners)\n",
    "ul = ur = ll = lr = centroid_point\n",
    "\n",
    "for point in corner_points:\n",
    "    x, y = point\n",
    "    # Upper Left (lowest x, highest y)\n",
    "    if x <= ul[0] and y >= ul[1]:\n",
    "        ul = point\n",
    "    # Upper Right (highest x, highest y)\n",
    "    if x >= ur[0] and y >= ur[1]:\n",
    "        ur = point\n",
    "    # Lower Left (lowest x, lowest y)\n",
    "    if x <= ll[0] and y <= ll[1]:\n",
    "        ll = point\n",
    "    # Lower Right (highest x, lowest y)\n",
    "    if x >= lr[0] and y <= lr[1]:\n",
    "        lr = point\n",
    "\n",
    "# Create a properly ordered corner points list\n",
    "corner_points = [ul, ur, lr, ll]\n",
    "polygon = Polygon(corner_points)\n",
    "print(corner_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original bounds: (227250.00000000076, 9353789.999999965, 227350.00000000076, 9353889.999999965)\n",
      "Rounded bounds: (227250.0, 9353790.0, 227350.0, 9353890.0)\n",
      "Size [m] 100.0 100.0\n"
     ]
    }
   ],
   "source": [
    "# Create a gdf from the polygon\n",
    "gdf = gpd.GeoDataFrame(index=[0], crs=gdf_pm.crs, geometry=[polygon])\n",
    "crs_utm = int(gdf_pm[\"UTM\"].iloc[0])\n",
    "gdf = gdf.to_crs(crs_utm)\n",
    "print(\"Original bounds:\", gdf.iloc[0].geometry.bounds)\n",
    "# Update geometry with rounded bounds\n",
    "gdf.geometry = gdf.geometry.apply(lambda geom: Polygon.from_bounds(*[round(bound) for bound in geom.bounds]))\n",
    "print(\"Rounded bounds:\", gdf.iloc[0].geometry.bounds)\n",
    "\n",
    "geometry_latlon = gdf.to_crs(\"EPSG:4326\").geometry.iloc[0]\n",
    "\n",
    "bounds = gdf.iloc[0].geometry.bounds\n",
    "span_x = bounds[2] - bounds[0]\n",
    "span_y = bounds[3] - bounds[1]\n",
    "print(\"Size [m]\", span_x, span_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"LCFM_LCM-10_v008\"\n",
    "resolution = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date range for the search\n",
    "year = 2020\n",
    "start_date = datetime(year, 1, 1).isoformat() + \"Z\"\n",
    "end_date = datetime(year, 12, 12).isoformat() + \"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAC query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items in the collection:\n",
      "- LCFM_LCM-10_V008_2020_20MKU_MAP\n",
      "- LCFM_LCM-10_V008_2020_19MHP_MAP\n"
     ]
    }
   ],
   "source": [
    "# Connect to the STAC API\n",
    "stac_api_url = \"https://www.stac.lcfm.dataspace.copernicus.eu/\"\n",
    "catalog = Client.open(stac_api_url)\n",
    "\n",
    "# Fetch items from the collection using the search method with spatial and temporal constraints\n",
    "search = catalog.search(\n",
    "    collections=[collection],\n",
    "    datetime=f\"{start_date}/{end_date}\",\n",
    "    intersects=geometry_latlon,\n",
    ")\n",
    "\n",
    "items = list(search.items())\n",
    "\n",
    "if items:\n",
    "    # Print items found in the collection\n",
    "    print(f\"Found {len(items)} items in the collection:\")\n",
    "    for item in items:\n",
    "        print(f\"- {item.id}\")\n",
    "else:\n",
    "    print(\"No items found in the collection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select item from the list with matching crs\n",
    "item = None\n",
    "for i in items:\n",
    "    if i.properties[\"proj:epsg\"] == crs_utm:\n",
    "        item = i\n",
    "        break\n",
    "if item:\n",
    "    print(item.id)\n",
    "    source_crs = crs_utm\n",
    "    source_bounds = bounds\n",
    "else:\n",
    "    # TODO: refine the selection of the item\n",
    "    item = min(items, key=lambda x: shape(x.geometry).centroid.distance(geometry_latlon.centroid))\n",
    "    source_crs = item.properties[\"proj:epsg\"]\n",
    "    # Reproject\n",
    "    source_bounds = gdf.to_crs(source_crs).iloc[0].geometry.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 session info\n",
    "# If profile, pass profile_name; otherwise use keys\n",
    "if auth_method == \"profile\":\n",
    "    b3 = boto3.Session(profile_name=profile)\n",
    "else:\n",
    "    b3 = boto3.Session(\n",
    "        aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "        aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    )\n",
    "\n",
    "aws_session = AWSSession(session=b3, endpoint_url=endpoint_url)\n",
    "\n",
    "# 3) Tell GDAL to use path-style + your endpoint\n",
    "gdal_env = stackstac.DEFAULT_GDAL_ENV.updated(\n",
    "    always={\n",
    "      \"session\":                 aws_session,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read MAP asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = [\"map\"]\n",
    "\n",
    "if profile == \"lcfm\":\n",
    "    for asset_key in assets:\n",
    "        item.assets[asset_key].href = item.assets[asset_key].extra_fields[\"alternate\"][\"local\"][\"href\"]\n",
    "\n",
    "# Now you can use stackstac with the modified STAC item\n",
    "map = stackstac.stack([item],\n",
    "                          assets=assets,\n",
    "                          bounds=bounds,\n",
    "                          resolution=resolution,\n",
    "                          epsg=source_crs,\n",
    "                          fill_value=np.uint8(255),\n",
    "                          dtype=np.uint8,\n",
    "                          rescale=False,\n",
    "                          gdal_env=gdal_env,\n",
    "                          ).isel(time=0)\n",
    "\n",
    "# Example to check the DataArray information\n",
    "# map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject\n",
    "if source_crs != crs_utm or True:\n",
    "    transform = from_bounds(*bounds, (span_x/resolution), (span_y/resolution))\n",
    "    map = map.rio.reproject(\n",
    "        f\"EPSG:{crs_utm}\",\n",
    "        resolution=resolution,\n",
    "        resampling=Resampling.nearest,\n",
    "        transform=transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error opening 's3://vito-upload/LCM-10/v008/tiles_utm/20/M/KU/2020/LCFM_LCM-10_V008_2020_20MKU_MAP.tif': RasterioIOError(\"'/vsis3/vito-upload/LCM-10/v008/tiles_utm/20/M/KU/2020/LCFM_LCM-10_V008_2020_20MKU_MAP.tif' does not exist in the file system, and is not recognized as a supported dataset name.\")",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCPLE_OpenFailedError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mrasterio/_base.pyx:310\u001b[39m, in \u001b[36mrasterio._base.DatasetBase.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mrasterio/_base.pyx:221\u001b[39m, in \u001b[36mrasterio._base.open_dataset\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mrasterio/_err.pyx:359\u001b[39m, in \u001b[36mrasterio._err.exc_wrap_pointer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCPLE_OpenFailedError\u001b[39m: '/vsis3/vito-upload/LCM-10/v008/tiles_utm/20/M/KU/2020/LCFM_LCM-10_V008_2020_20MKU_MAP.tif' does not exist in the file system, and is not recognized as a supported dataset name.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRasterioIOError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/stackstac/rio_reader.py:325\u001b[39m, in \u001b[36mAutoParallelRioReader._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     ds = \u001b[43mSelfCleaningDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mrasterio/_base.pyx:312\u001b[39m, in \u001b[36mrasterio._base.DatasetBase.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRasterioIOError\u001b[39m: '/vsis3/vito-upload/LCM-10/v008/tiles_utm/20/M/KU/2020/LCFM_LCM-10_V008_2020_20MKU_MAP.tif' does not exist in the file system, and is not recognized as a supported dataset name.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Extract the bands (assuming the order is B04=0, B03=1, B02=2)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m map_asset = \u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mband\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmap\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m[\u001b[32m0\u001b[39m,:,:]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Plot the RGB image\u001b[39;00m\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/xarray/core/dataarray.py:823\u001b[39m, in \u001b[36mDataArray.values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    810\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    811\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m    812\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    813\u001b[39m \u001b[33;03m    The array's data converted to numpy.ndarray.\u001b[39;00m\n\u001b[32m    814\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    821\u001b[39m \u001b[33;03m    to this array may be reflected in the DataArray as well.\u001b[39;00m\n\u001b[32m    822\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/xarray/core/variable.py:508\u001b[39m, in \u001b[36mVariable.values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m    507\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/xarray/core/variable.py:302\u001b[39m, in \u001b[36m_as_array_or_item\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_as_array_or_item\u001b[39m(data):\n\u001b[32m    289\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[33;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[32m    291\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m \u001b[33;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     data = np.asarray(data)\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data.ndim == \u001b[32m0\u001b[39m:\n\u001b[32m    304\u001b[39m         kind = data.dtype.kind\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/dask/array/core.py:1748\u001b[39m, in \u001b[36mArray.__array__\u001b[39m\u001b[34m(self, dtype, copy, **kwargs)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   1742\u001b[39m     warnings.warn(\n\u001b[32m   1743\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt acquire a memory view of a Dask array. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1744\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis will raise in the future.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1745\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   1746\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1748\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[38;5;66;03m# Apply requested dtype and convert non-numpy backends to numpy.\u001b[39;00m\n\u001b[32m   1751\u001b[39m \u001b[38;5;66;03m# If copy is True, numpy is going to perform its own deep copy\u001b[39;00m\n\u001b[32m   1752\u001b[39m \u001b[38;5;66;03m# after this method returns.\u001b[39;00m\n\u001b[32m   1753\u001b[39m \u001b[38;5;66;03m# If copy is None, finalize() ensures that the returned object\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;66;03m# does not share memory with an object stored in the graph or on a\u001b[39;00m\n\u001b[32m   1755\u001b[39m \u001b[38;5;66;03m# process-local Worker.\u001b[39;00m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(x, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/dask/base.py:370\u001b[39m, in \u001b[36mDaskMethodsMixin.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    347\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[32m    348\u001b[39m \n\u001b[32m    349\u001b[39m \u001b[33;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     (result,) = \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/dask/base.py:656\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    653\u001b[39m     postcomputes.append(x.__dask_postcompute__())\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, *a) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/stackstac/to_dask.py:189\u001b[39m, in \u001b[36mfetch_raster_window\u001b[39m\u001b[34m(reader_table, slices, dtype, fill_value)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# Only read if the window we're fetching actually overlaps with the asset\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m windows.intersect(current_window, asset_window):\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# NOTE: when there are multiple assets, we _could_ parallelize these reads with our own threadpool.\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# However, that would probably increase memory usage, since the internal, thread-local GDAL datasets\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# would end up copied to even more threads.\u001b[39;00m\n\u001b[32m    187\u001b[39m \n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# TODO when the Reader won't be rescaling, support passing `output` to avoid the copy?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     data = \u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m all_empty:\n\u001b[32m    192\u001b[39m         \u001b[38;5;66;03m# Turn `output` from a broadcast-trick array to a real array, so it's writeable\u001b[39;00m\n\u001b[32m    193\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    194\u001b[39m             np.isnan(data)\n\u001b[32m    195\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m np.isnan(fill_value)\n\u001b[32m    196\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m np.equal(data, fill_value)\n\u001b[32m    197\u001b[39m         ).all():\n\u001b[32m    198\u001b[39m             \u001b[38;5;66;03m# Unless the data we just read is all empty anyway\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/stackstac/rio_reader.py:383\u001b[39m, in \u001b[36mAutoParallelRioReader.read\u001b[39m\u001b[34m(self, window, **kwargs)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, window: Window, **kwargs) -> np.ndarray:\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m     reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    385\u001b[39m         result = reader.read(\n\u001b[32m    386\u001b[39m             window=window,\n\u001b[32m    387\u001b[39m             out_dtype=\u001b[38;5;28mself\u001b[39m.dtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m             **kwargs,\n\u001b[32m    392\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/stackstac/rio_reader.py:379\u001b[39m, in \u001b[36mAutoParallelRioReader.dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_lock:\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m         \u001b[38;5;28mself\u001b[39m._dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Private/lcfm-validation-extraction/.venv/lib64/python3.11/site-packages/stackstac/rio_reader.py:334\u001b[39m, in \u001b[36mAutoParallelRioReader._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m             warnings.warn(msg)\n\u001b[32m    330\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m NodataReader(\n\u001b[32m    331\u001b[39m                 dtype=\u001b[38;5;28mself\u001b[39m.dtype, fill_value=\u001b[38;5;28mself\u001b[39m.fill_value\n\u001b[32m    332\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ds.count != \u001b[32m1\u001b[39m:\n\u001b[32m    336\u001b[39m     nr_of_bands = ds.count\n",
      "\u001b[31mRuntimeError\u001b[39m: Error opening 's3://vito-upload/LCM-10/v008/tiles_utm/20/M/KU/2020/LCFM_LCM-10_V008_2020_20MKU_MAP.tif': RasterioIOError(\"'/vsis3/vito-upload/LCM-10/v008/tiles_utm/20/M/KU/2020/LCFM_LCM-10_V008_2020_20MKU_MAP.tif' does not exist in the file system, and is not recognized as a supported dataset name.\")"
     ]
    }
   ],
   "source": [
    "# Extract the bands (assuming the order is B04=0, B03=1, B02=2)\n",
    "map_asset = map.sel(band=\"map\").values[0,:,:]\n",
    "\n",
    "# Plot the RGB image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(map_asset, cmap='gray', vmin=0, vmax=254)  # Use 'gray' for single band\n",
    "plt.title(\"Map\")\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GeoTIFF → s1_data.tif\n"
     ]
    }
   ],
   "source": [
    "# Write out\n",
    "profile_kwargs = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"dtype\": str(map_asset.dtype),     # make sure your data actually fits this type\n",
    "    \"compress\": \"LZW\",    # lossless LZW compression\n",
    "}\n",
    "\n",
    "output_file = \"map.tif\"\n",
    "map_asset.name = map_asset.band.values[0]\n",
    "map_asset.rio.to_raster(output_file, **profile_kwargs)\n",
    "\n",
    "print(f\"Saved GeoTIFF → {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
